{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running example in Jupyter Notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import nucleus_api\n",
    "from nucleus_api.rest import ApiException\n",
    "import nucleus_api.api.nucleus_api as nucleus_helper\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    ip = get_ipython()\n",
    "    running_notebook = True\n",
    "except NameError:\n",
    "    running_notebook = False\n",
    "\n",
    "if running_notebook:\n",
    "    print('Running example in Jupyter Notebook')\n",
    "else:\n",
    "    print('Running example in script mode')\n",
    "    \n",
    "configuration = nucleus_api.Configuration()\n",
    "configuration.host = 'https://7h4tcw9nej.execute-api.us-west-2.amazonaws.com/v2'\n",
    "configuration.api_key['x-api-key'] = 'GUgIdygFRta54fwQ0G1S9A'\n",
    "\n",
    "# Create API instance\n",
    "api_instance = nucleus_api.NucleusApi(nucleus_api.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Get topic historical analysis for boeing_corpfilings ----------------\n",
      "Printing historical metrics data...\n",
      "NOTE: historical metrics data can be plotted when running the example in Jupyter Notebook\n",
      "Topic 0 table contents;comprehensive income;income tax;condensed consolidated;boeing company;derivative instruments;financial statements;tax comprehensive\n",
      "    Timestamps: ['2019-08-02 01:32']\n",
      "    Strengths: ['NaN']\n",
      "    Consensuses: ['NaN']\n",
      "    Sentiments: ['NaN']\n",
      "----------------\n",
      "Topic 1 earnings operations;compared period;partially offset;increased compared;decreased compared;operations increased;operations decreased;commercial airplanes\n",
      "    Timestamps: ['2019-08-02 01:32']\n",
      "    Strengths: ['NaN']\n",
      "    Consensuses: ['NaN']\n",
      "    Sentiments: ['NaN']\n",
      "----------------\n",
      "Topic 2 cash equivalents;cash cash;operating activities;cash flows;activities cash;cash operating;financing activities;investing activities\n",
      "    Timestamps: ['2019-08-02 01:32']\n",
      "    Strengths: ['NaN']\n",
      "    Consensuses: ['NaN']\n",
      "    Sentiments: ['NaN']\n",
      "----------------\n",
      "Topic 3 fair value;level level;total fair;accounts receivable;notes receivable;carrying total;capital lease;lease obligations\n",
      "    Timestamps: ['2019-08-02 01:32']\n",
      "    Strengths: ['NaN']\n",
      "    Consensuses: ['NaN']\n",
      "    Sentiments: ['NaN']\n",
      "----------------\n",
      "Topic 4 pension postretirement;core operating;operating earnings;unallocated items;postretirement benefit;items eliminations;benefit expense;unallocated pension\n",
      "    Timestamps: ['2019-08-02 01:32']\n",
      "    Strengths: ['NaN']\n",
      "    Consensuses: ['NaN']\n",
      "    Sentiments: ['NaN']\n",
      "----------------\n",
      "Topic 5 customer financing;sharebased payment;payment arrangements;property plant;plant equipment;equivalents cash;tax benefits;excess tax\n",
      "    Timestamps: ['2019-08-02 01:32']\n",
      "    Strengths: ['NaN']\n",
      "    Consensuses: ['NaN']\n",
      "    Sentiments: ['NaN']\n",
      "----------------\n",
      "Topic 6 pension plans;period tax;arising period;defined benefit;periodic pension;benefit pension;postretirement benefits;pension cost\n",
      "    Timestamps: ['2019-08-02 01:32']\n",
      "    Strengths: ['NaN']\n",
      "    Consensuses: ['NaN']\n",
      "    Sentiments: ['NaN']\n",
      "----------------\n",
      "Topic 7 vice president;senior vice;president manager;president chief;executive vice;positions include;joined boeing;previous positions\n",
      "    Timestamps: ['2019-08-02 01:32']\n",
      "    Strengths: ['NaN']\n",
      "    Consensuses: ['NaN']\n",
      "    Sentiments: ['NaN']\n",
      "----------------\n",
      "Plotting historical metrics data...\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = \"boeing_corpfilings\"   # str | Dataset name.\n",
    "print('------------ Get topic historical analysis for {} ----------------'.format(dataset))\n",
    "\n",
    "update_period = \"d\" # str | Frequency at which the historical anlaysis is performed. choices=[\"d\",\"m\",\"H\",\"M\"] (default to d)\n",
    "query = '' # str | Fulltext query, using mysql MATCH boolean query format. Example, (\\\"word1\\\" OR \\\"word2\\\") AND (\\\"word3\\\" OR \\\"word4\\\") (optional)\n",
    "custom_stop_words = [''] # str | List of stop words (optional)\n",
    "num_topics = 8 # int | Number of topics to be extracted from the dataset. (optional) (default to 8)\n",
    "num_keywords = 8 # int | Number of keywords per topic that is extracted from the dataset. (optional) (default to 8)\n",
    "inc_step = 1 # int | Number of increments of the udpate period in between two historical computations. (optional) (default to 1)\n",
    "excluded_docs = [''] # str | List of document IDs that should be excluded from the analysis. Example, [\"docid1\", \"docid2\", ..., \"docidN\"]  (optional)\n",
    "custom_dict_file = {} # file | Custom sentiment dictionary JSON file. Example, {\"field1\": value1, ..., \"fieldN\": valueN} (optional)\n",
    "remove_redundancies = False # bool | If True, this option removes quasi-duplicates from the analysis. A quasi-duplicate would have the same NLP representation, but not necessarily the exact same text. (optional) (default True)\n",
    "\n",
    "metadata_selection =\"\" # dict | JSON object specifying metadata-based queries on the dataset, of type {\"metadata_field\": \"selected_values\"} (optional)\n",
    "time_period = \"\"     # str | Time period selection. Choices: [\"1M\",\"3M\",\"6M\",\"12M\",\"3Y\",\"5Y\",\"\"] (optional)\n",
    "period_start = \"\" # str | Start date for the period to analyze within the dataset. Format: \"YYYY-MM-DD HH:MM:SS\"\n",
    "period_end = \"\" # str | End date for the period to analyze within the dataset. Format: \"YYYY-MM-DD HH:MM:SS\"\n",
    "api_response = None\n",
    "try:\n",
    "    payload = nucleus_api.TopicHistoryModel(\n",
    "        dataset=dataset, \n",
    "        time_period=time_period, \n",
    "        update_period=update_period, \n",
    "        query=query, \n",
    "        custom_stop_words=custom_stop_words, \n",
    "        num_topics=num_topics, \n",
    "        num_keywords=num_keywords, \n",
    "        metadata_selection=metadata_selection, \n",
    "        inc_step=inc_step, \n",
    "        excluded_docs=excluded_docs,\n",
    "        custom_dict_file=custom_dict_file)\n",
    "    api_response = api_instance.post_topic_historical_analysis_api(payload)\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    print(e)\n",
    "\n",
    "print('Printing historical metrics data...')\n",
    "print('NOTE: historical metrics data can be plotted when running the example in Jupyter Notebook')\n",
    "\n",
    "for i,res in enumerate(api_response.result):\n",
    "    print('Topic', i, res.keywords)\n",
    "    print('    Timestamps:', res.time_stamps)\n",
    "    print('    Strengths:', res.strengths)\n",
    "    print('    Consensuses:', res.consensuses)\n",
    "    print('    Sentiments:', res.sentiments)\n",
    "    print('----------------')\n",
    "            \n",
    "# chart the historical metrics when running in Jupyter Notebook\n",
    "if running_notebook:\n",
    "    print('Plotting historical metrics data...')\n",
    "    historical_metrics = []\n",
    "    for res in api_response.result:\n",
    "        # construct a list of historical metrics dictionaries for charting\n",
    "        historical_metrics.append({\n",
    "            'topic'    : res.keywords,\n",
    "            'time_stamps' : np.array(res.time_stamps),\n",
    "            'strength' : np.array(res.strengths, dtype=np.float32),\n",
    "            'consensus': np.array(res.consensuses, dtype=np.float32), \n",
    "            'sentiment': np.array(res.sentiments, dtype=np.float32)})\n",
    "\n",
    "    selected_topics = range(len(historical_metrics)) \n",
    "    #nucleus_helper.topic_charts_historical(historical_metrics, selected_topics, True)\n",
    "\n",
    "print('-------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- List available datasets ---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-02 00:59:50,831 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))': /v2/datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 datasets in the database:\n",
      "     boeing_corpfilings\n",
      "     dataset_test\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('---------------- List available datasets ---------------------')\n",
    "try:\n",
    "    api_response = api_instance.get_list_datasets()\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling DatasetsApi->get_list_datasets: %s\\n\" % e)\n",
    "\n",
    "list_datasets = api_response.result\n",
    "\n",
    "print(len(list_datasets), 'datasets in the database:')\n",
    "for ds in list_datasets:\n",
    "    print('    ', ds.name)\n",
    "    \n",
    "print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
